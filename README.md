# Hi there, I'm Yifei ZHOU! 👋

🎓 **PhD Candidate** in Computational Neuroscience at Institute of Automation, Chinese Academy of Sciences.
🔬 **Research Focus:** Modeling the auditory system using data-driven deep learning approaches.  
🤖 **Current Interest:** Exploring Multimodal AI, AI Agents, and their applications in perceptual tasks.  
🌱 **Learning:** Sharpening my skills in Python, PyTorch, and Multi-modal LLMs.

---

## 🛠️ Tech Stack & Skills
**Programming:** `Python` | `MATLAB` 
**ML/DL Frameworks:** `PyTorch` | `TensorFlow` 
**Tools:** `Git` | `Docker` (Basic) | `Linux` 
**Areas of Interest:** `Computational Neuroscience` | `Deep Learning` | `Multimodal Learning` | `AI Agents`

---

## 📂 Featured Projects


### 🧠 [Project 1: Cross-Species Auditory Cascade Models for Pitch Perception]
**Description:** This is my core Ph.D. research project. It involves building a series of AI-driven auditory peripheral cascade models with parameters derived from different species (e.g., guinea pig, cat, human). The goal is to simulate the transformation of sound waves into neural representations and investigate how these species-specific processing pipelines influence the emergence of pitch perception mechanisms in higher-level neural networks. This data-driven approach aims to bridge computational neuroscience and deep learning to explore fundamental questions in auditory perception.
**Key Features:**
-   **Biologically-Inspired Design:** Models incorporate species-specific neurophysiological parameters (e.g., basilar membrane tuning, nerve fiber response characteristics).
-   **Deep Learning Framework:** Utilizes deep neural networks (CNNs, Transformers) as a flexible framework to learn the mapping from simulated auditory nerve patterns to perceptual phenomena.
-   **Comparative Analysis:** Systematically compares model performance across "species" to hypothesize about evolutionary and functional adaptations in auditory processing.
**Tech:** Python | PyTorch | TensorFlow | Psychoacoustics Metrics | Neurophysiology Data Analysis
**Link:** 【Link to your Ph.D. project repository】
**Status:** 🔬 Active Research - Initial results expected in 6 months.

### [Project 2: CNN-based Auditory System Modeling]
**Description:** My graduation design project involved building and training CNN models to simulate and understand the human auditory processing mechanism.
**Tech:** Python, CNN, TensorFlow/Keras
**Link:** --

### [Project 3: Multimodal GUI Automation Agent (In Progress)]
**Description:** Developing a proof-of-concept AI agent that uses vision-language models to understand screen content and perform basic GUI automation tasks. This is my hands-on project to learn about multi-modal AI agents.
**Tech:** Python, OpenAI API, PyAutoGUI, CLIP
**Link:** ...

---

## 📊 GitHub Stats & Overview

![Your GitHub Stats](https://github-readme-stats.vercel.app/api?username=rubberpone&show_icons=true&hide_border=true&theme=radical)

![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=rubberpone&layout=compact&hide_border=true&theme=radical)

*(这些动态统计图会自动更新，非常直观。你现在可能数据不多，但随着你活跃度提升，它会变得越来越好看)*

---

## 📫 How to Reach Me
- **Email:**  431240121@qq.com
- **LinkedIn:** [周羿霏](https://www.linkedin.com/in/%E7%BE%BF%E9%9C%8F-%E5%91%A8-319929385/)
- **Twitter/X:** --

*Open to research internships and collaborations in AI! Let's connect!*
